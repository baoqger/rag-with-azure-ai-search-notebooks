{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RAG answer quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import dotenv\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "azure_credential = azure.identity.AzureDeveloperCliCredential(tenant_id=os.getenv(\"AZURE_TENANT_ID\"))\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = OpenAI(\n",
    "    base_url=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com/openai/v1\",\n",
    "    api_key=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "AZURE_SEARCH_FULL_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\", \"gptkbindex\")\n",
    "AZURE_SEARCH_EMBEDDING_FIELD = os.getenv(\"AZURE_SEARCH_EMBEDDING_FIELD\", \"embedding\")\n",
    "\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answer for a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A product manager at Contoso Electronics is responsible for developing and implementing product strategies and plans that support business objectives and growth. They lead a team in executing these strategies, research market trends and customer needs, oversee product roadmaps, manage product life cycles from concept to launch, and monitor product performance and customer feedback. They also identify strategic partnership opportunities, manage product budgets, develop pricing and promotional strategies, and collaborate with cross-functional teams to ensure products meet customer needs. The role requires analyzing competitors and market trends to keep products competitive and successful in the marketplace [role_library.pdf#page=17, #page=23, #page=29].\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What does a product manager do?\"\n",
    "user_question_vector = get_embedding(user_question)\n",
    "\n",
    "r = search_client.search(\n",
    "        user_question,\n",
    "        top=5, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=AZURE_SEARCH_EMBEDDING_FIELD)],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\\n\".join([f\"[{doc['sourcepage']}]: {doc['content']}\\n\" for doc in r])\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Assistant helps company employees questions about the employee handbook. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below.\n",
    "Each source has a name followed by colon and the actual information, include the source name for each fact you use.\n",
    "Use square brackets to reference the source, for example [info1.txt].\n",
    "\"\"\"\n",
    "USER_MESSAGE = user_question + \"\\nSources: \" + sources\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the answer quality\n",
    "\n",
    "We can use the `azure-ai-evaluation` package to run GPT-based evaluators on the RAG responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 5.0, 'gpt_relevance': 5.0, 'relevance_reason': 'The response fully addresses the query with accurate and complete information about the role of a product manager, and it includes additional insights that enhance understanding.'}\n",
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The RESPONSE is fully grounded in the CONTEXT, accurately reflecting the responsibilities and qualifications of a product manager as described in the provided material.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration, GroundednessEvaluator, RelevanceEvaluator\n",
    "\n",
    "model_config: AzureOpenAIModelConfiguration = {\n",
    "    \"azure_endpoint\": f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "}\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    query=user_question,\n",
    "    response=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(relevance_score)\n",
    "\n",
    "# If you see NaN, make sure you're using a GPT-4 level model\n",
    "groundedness_score = groundedness_eval(\n",
    "    response=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(groundedness_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
